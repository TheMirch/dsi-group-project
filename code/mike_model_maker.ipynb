{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d38668-ea6b-4e59-ab05-9ab4eafc2927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3236e2c-7dd3-47c5-878b-b22c1bab12d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class aviation_data_model:\n",
    "    def __init__(self, x, y, drop_categories = None, test_size = 0.3, random_state = 2023):\n",
    "        self.x = x.copy()\n",
    "        self.drop_categories = drop_categories\n",
    "        self.y = y\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        self.model = None\n",
    "        self.x_oh = None\n",
    "        self.x_con = None\n",
    "        self.results = None\n",
    "        self.pvalues = None\n",
    "\n",
    "        \n",
    "    def one_hot(self):\n",
    "        #Check to see if dummy parameter passed correctly\n",
    "        if type(self.drop_categories[0]) == tuple:\n",
    "            \n",
    "            categories = []\n",
    "            for i, j in self.drop_categories:\n",
    "                # Collect subset of columns to dummify\n",
    "                categories.append(i)\n",
    "                \n",
    "                # If a specific drop value has been given for a column, add a 0- to it so it is 'first' and drops accordingly\n",
    "                if j != 'first':\n",
    "                    self.x[i] = np.where(self.x[i] == j, '0-' + j, self.x[i])\n",
    "        else:\n",
    "            raise TypeError('Invalid OneHotEncoder values. Use None or a list of tuples of (column name, category name')\n",
    "            \n",
    "        self.x_oh = pd.get_dummies(data= self.x, columns = categories, drop_first=True)\n",
    "        # Log line - uncomment below to check shapes after important steps\n",
    "        # print(f\"OneHot Resulting Shape: {self.x_oh.shape}\")\n",
    "        return self.x_oh\n",
    "    \n",
    "    def train_test(self, x, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        return (X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    \n",
    "    def fit_binomial(self, link = 'logit'):\n",
    "        # Start with OneHotEncoding if given\n",
    "        if self.drop_categories:\n",
    "            oh = self.one_hot()\n",
    "        else:\n",
    "            oh = self.x\n",
    "            \n",
    "        # Add column for constant per statsmodels GLM requirements\n",
    "        x_con = sm.add_constant(oh[list(oh.columns)])\n",
    "        self.x_con = x_con\n",
    "        \n",
    "        # Log line - uncomment below to check shapes after important steps\n",
    "        # print(f\"After constant Resulting Shape: {self.x_con.shape}\")\n",
    "        \n",
    "        #Train Test Split\n",
    "        X_train, X_test, y_train, y_test = self.train_test(x_con, self.y)\n",
    "\n",
    "        \n",
    "        # Log lines - uncomment below to check shapes after important steps\n",
    "        # print(f\"After tts X_train Resulting Shape: {X_train.shape}\")\n",
    "        # print(f\"After tts X_test Resulting Shape: {X_test.shape}\")\n",
    "        # print(f\"After tts y_train Resulting Shape: {y_train.shape}\")\n",
    "        # print(f\"After tts y_test Resulting Shape: {y_test.shape}\")\n",
    "        \n",
    "        if link == 'logit':\n",
    "            link_function = sm.families.links.Logit()\n",
    "        elif link == 'probit':\n",
    "            link_function = sm.families.links.Probit()\n",
    "        \n",
    "        #Make and fit a model\n",
    "        glm_bin = sm.GLM(\n",
    "            y_train,\n",
    "            X_train,\n",
    "            family=sm.families.Binomial(link=link_function)).fit()\n",
    "        \n",
    "        #Stash results as accessible attributes\n",
    "        self.results = glm_bin.summary()\n",
    "        self.model = glm_bin\n",
    "        self.pvalues = np.round(glm_bin.pvalues, 4).to_frame().sort_values(by = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489d814b-d6e4-4bd7-b7e0-ecdb6f98d5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../datasets/alaska_single_engine_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d833d7d-9288-437d-a330-d6d294f58187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['model'] = df2['model'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29cd2b7d-8bb6-4474-95f7-d580ab555c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['make'] = df2['make'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece4e498-1df9-4694-b9a5-ef379f7b8326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['occurred_near_airport'] = 1 - df2['airport_name'].str.contains('Unknown').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f709508c-0db8-4372-86e0-7343fdedc4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['purpose_of_flight'] = df2['purpose_of_flight'].map(lambda x: 'UNK' if x=='Unknown' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a475b0f1-0579-4423-8d88-cce6b362a22f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_top_model(model, top_x):\n",
    "    top_list = list(df2['model'].value_counts()[:top_x + 1].index.str.upper())\n",
    "    return True if model.upper() in top_list else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c69f2cd-7c93-47c1-be85-6016630a83a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['model'] = [x.upper() if is_top_model(x,200) else 'UNCOMMON MODEL' for x in df2['model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71052842-0636-4ccc-b6fe-56ea4c865312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_top_make(make, top_x):\n",
    "    top_list = list(df2['make'].value_counts()[:top_x + 1].index.str.upper())\n",
    "    return True if make.upper() in top_list else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9bf0136-0b84-4f42-86d2-44fd29e4998e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['make'] = [x.upper() if is_top_make(x,50) else 'UNCOMMON MAKE' for x in df2['make']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbeaac82-48b6-4bb3-b1c0-cbc19c607e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df2.drop(['ntsb_no', 'probable_cause', 'airport_name', 'event_type', 'mkey', 'city', 'n', 'has_safety_rec', 'report_type', 'highest_injury_level', 'fatal_injury_count', 'serious_injury_count', 'minor_injury_count', 'airport_id', 'far', 'aircraft_damage', 'operator', 'event_year', 'event_season', 'event_day', 'aircraft_category', 'has_injury', 'event_time','has_aircraft_damage'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e510b381-9e47-4204-a91a-32ffdce32191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_X = pd.get_dummies(data= X, columns = ['make', 'model', 'scheduled', 'purpose_of_flight', 'weather_condition', 'event_month', 'event_hour'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadccba-aa93-4ccd-881d-c212d9908db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2a5039-0286-4783-9014-79af22c8aeb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df2['has_injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca80330e-f160-48a3-84b7-d17fcf864c77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m\n\u001b[0;32m      3\u001b[0m binomial_model_1 \u001b[38;5;241m=\u001b[39m aviation_data_model( X, y, [\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Include tuples of (column name, specific value you want dropped)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Just put 'first' if you don't care about dropping a specific value\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_hour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m ])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# call the fit_binomial() model to get it!\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m binomial_model_1\u001b[38;5;241m.\u001b[39mfit_binomial()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# access the results\u001b[39;00m\n\u001b[0;32m     19\u001b[0m res \u001b[38;5;241m=\u001b[39m binomial_model_1\u001b[38;5;241m.\u001b[39mresults\n",
      "Cell \u001b[1;32mIn[2], line 63\u001b[0m, in \u001b[0;36maviation_data_model.fit_binomial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_test(x_con, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Log lines - uncomment below to check shapes after important steps\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# print(f\"After tts X_train Resulting Shape: {X_train.shape}\")\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print(f\"After tts X_test Resulting Shape: {X_test.shape}\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#Make and fit a model\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m glm_bin \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mGLM(\n\u001b[0;32m     64\u001b[0m     y_train,\n\u001b[0;32m     65\u001b[0m     X_train,\n\u001b[0;32m     66\u001b[0m     family\u001b[38;5;241m=\u001b[39msm\u001b[38;5;241m.\u001b[39mfamilies\u001b[38;5;241m.\u001b[39mBinomial(link\u001b[38;5;241m=\u001b[39msm\u001b[38;5;241m.\u001b[39mfamilies\u001b[38;5;241m.\u001b[39mlinks\u001b[38;5;241m.\u001b[39mLogit()))\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#Stash results as accessible attributes\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m glm_bin\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:325\u001b[0m, in \u001b[0;36mGLM.__init__\u001b[1;34m(self, endog, exog, family, offset, exposure, freq_weights, var_weights, missing, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights \u001b[38;5;241m=\u001b[39m freq_weights\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights \u001b[38;5;241m=\u001b[39m var_weights\n\u001b[1;32m--> 325\u001b[0m \u001b[38;5;28msuper\u001b[39m(GLM, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    326\u001b[0m                           offset\u001b[38;5;241m=\u001b[39moffset, exposure\u001b[38;5;241m=\u001b[39mexposure,\n\u001b[0;32m    327\u001b[0m                           freq_weights\u001b[38;5;241m=\u001b[39mfreq_weights,\n\u001b[0;32m    328\u001b[0m                           var_weights\u001b[38;5;241m=\u001b[39mvar_weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_inputs(family, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexposure, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog,\n\u001b[0;32m    330\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(PandasData, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# SAMPLE!\n",
    "# create a new object that is ultimately a fitted binomial model\n",
    "binomial_model_1 = aviation_data_model( X, y, [\n",
    "    # Include tuples of (column name, specific value you want dropped)\n",
    "    # Just put 'first' if you don't care about dropping a specific value\n",
    "    ('make', 'CESSNA'),\n",
    "    ('model', 'PA-18'),\n",
    "    ('scheduled', 'first'),\n",
    "    ('purpose_of_flight', 'first'),\n",
    "    ('weather_condition', 'first'),\n",
    "    ('event_month', 'first'),\n",
    "    ('event_hour', 'first')\n",
    "])\n",
    "\n",
    "# call the fit_binomial() model to get it!\n",
    "binomial_model_1.fit_binomial()\n",
    "\n",
    "# access the results\n",
    "res = binomial_model_1.results\n",
    "# or the p values\n",
    "pvalues = binomial_model_1.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cd523-8ec3-4200-bb9f-c54ca87a2104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c832817-1d70-4f3a-be4f-7f8f7ff2a55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ce957-b4a4-444b-bc0a-2a7aab55c333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = glm1.train_test(glm2.x_con, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5394cd-9163-4108-ba3b-46c0f3024cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859afbb0-b385-4aeb-b37e-aabee9a4fde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbd48d-f83d-4f57-9d25-0012f2b44283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "        glm_bin = sm.GLM(\n",
    "            y_tr,\n",
    "            X_tr,\n",
    "            family=sm.families.Binomial(link=sm.families.links.Logit())).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db45a54-a22d-480a-8978-373bc6972505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glm_bin.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecd6a2-94e0-4955-be99-b78a9f58a46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
